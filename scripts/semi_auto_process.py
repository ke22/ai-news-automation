#!/usr/bin/env python
"""
åŠè‡ªå‹• AI æ–°èè™•ç†ç³»çµ±
å¯¦ç¾å…©æ®µå¼å·¥ä½œæµï¼šAIæŒ‘é¸ -> äººå·¥ç¯©é¸ -> AIç”¢å‡º
"""

import os
import sys
import json
from datetime import datetime, timezone
from dateutil import parser as dtparser

# Add project root to Python path for imports
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from scripts.utils import today_path, write_json, read_json, load_yaml, to_display_date


def load_articles():
    """è¼‰å…¥åŸå§‹æ–°èè³‡æ–™"""
    date_path = today_path()
    base = f"data/{date_path}"
    items = read_json(f"{base}/raw_news.json", default=[])
    return items


def ai_initial_scoring(items):
    """ç¬¬ä¸€éšæ®µï¼šAI åˆæ­¥è©•åˆ†èˆ‡åˆ†é¡"""
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âŒ GEMINI_API_KEY æœªè¨­å®š")
        return []

    try:
        import google.generativeai as genai

        genai.configure(api_key=api_key)
        model = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
        gen_model = genai.GenerativeModel(model)

        print("ğŸ¤– AI æ­£åœ¨é€²è¡Œåˆæ­¥è©•åˆ†èˆ‡åˆ†é¡...")

        scored_items = []
        for i, item in enumerate(items[:20]):  # é™åˆ¶å‰20ç¯‡
            prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ AI ç”¢æ¥­å…§å®¹ç­–å±•äººã€‚

è«‹å°ä»¥ä¸‹æ–°èé€²è¡Œè©•åˆ†èˆ‡åˆ†é¡ï¼š

æ¨™é¡Œï¼š{item['title']}
æ‘˜è¦ï¼š{item.get('summary', '')}
ä¾†æºï¼š{item.get('source', '')}
æ™‚é–“ï¼š{item.get('published_at', '')}

è«‹è¼¸å‡º JSON æ ¼å¼ï¼š
{{
    "category": "æ¨¡å‹ç™¼å¸ƒ/AIé–‹ç™¼å·¥å…·/ä¼æ¥­æ‡‰ç”¨/é‡å¤§èè³‡/ç ”ç©¶çªç ´",
    "key_point": "ä¸€å¥é‡é»ï¼ˆâ‰¤30å­—ï¼‰",
    "key_data": "é—œéµæ•¸æ“šï¼ˆæœ€å¤š3å€‹ã€ŒæŒ‡æ¨™:æ•¸å€¼ã€ï¼›ç¼ºå‰‡å¯«ã€Œâ€”ã€ï¼‰",
    "tech_score": 0-5,
    "impact_score": 0-5,
    "practical_score": 0-5,
    "timely_score": 0-5,
    "total_score": "å››é …åŠ æ¬Šæ±‚å’Œï¼Œä¿ç•™1ä½å°æ•¸",
    "hours_ago": "è·ä»Šå¹¾å°æ™‚",
    "cluster_id": "åŒé¡Œç›¸åŒIDï¼ˆå¦‚æœèˆ‡å…¶ä»–æ–°èç›¸åŒï¼‰"
}}"""

            response = gen_model.generate_content(
                prompt, generation_config=genai.types.GenerationConfig(temperature=0.2)
            )

            try:
                data = json.loads(response.text.strip())
                scored_item = {"id": i + 1, "original": item, "ai_analysis": data}
                scored_items.append(scored_item)
                print(f"âœ… å·²è©•åˆ†ç¬¬ {i+1} ç¯‡")
            except Exception as e:
                print(f"âŒ ç¬¬ {i+1} ç¯‡è©•åˆ†å¤±æ•—: {e}")
                continue

        return scored_items

    except Exception as ex:
        print(f"âŒ AI è©•åˆ†å¤±æ•—ï¼š{ex}")
        return []


def generate_candidate_board(scored_items):
    """ç”Ÿæˆå€™é¸çœ‹æ¿"""
    print("\nğŸ“‹ å€™é¸çœ‹æ¿")
    print("=" * 80)
    print(
        f"{'#':<3} {'é¡åˆ¥':<12} {'æ¨™é¡Œ':<40} {'ä¸€å¥é‡é»':<25} {'ç¸½åˆ†':<6} {'æ™‚æ•ˆ':<8} {'ä¾†æº':<15}"
    )
    print("-" * 80)

    for item in scored_items:
        analysis = item["ai_analysis"]
        title = (
            item["original"]["title"][:35] + "..."
            if len(item["original"]["title"]) > 35
            else item["original"]["title"]
        )
        key_point = (
            analysis.get("key_point", "")[:20] + "..."
            if len(analysis.get("key_point", "")) > 20
            else analysis.get("key_point", "")
        )

        print(
            f"{item['id']:<3} {analysis.get('category', '')[:10]:<12} {title:<40} {key_point:<25} {analysis.get('total_score', 0):<6} {analysis.get('hours_ago', 0):<8} {item['original'].get('source', '')[:12]:<15}"
        )

    print("\nğŸ“ æ“ä½œæŒ‡ä»¤ï¼š")
    print("#é¸æ“‡ 1 3 5 7 9ï¼ˆé¸æ“‡æŒ‡å®šç·¨è™Ÿçš„æ–°èï¼‰")
    print("#é‡æœ é—œéµè©A,é—œéµè©Bï¼ˆé‡æ–°æœå°‹ï¼‰")
    print("#éæ¿¾ é¡åˆ¥=ç ”ç©¶çªç ´ï¼ˆæŒ‰æ¢ä»¶éæ¿¾ï¼‰")
    print("#è£œè­‰æ“š 4ï¼ˆè£œå……ç‰¹å®šæ–°èçš„è­‰æ“šï¼‰")


def manual_selection_and_processing():
    """äººå·¥é¸æ“‡èˆ‡è™•ç†"""
    print("\nğŸ¯ è«‹è¼¸å…¥æ‚¨çš„é¸æ“‡æŒ‡ä»¤ï¼š")
    print("ç¯„ä¾‹ï¼š#é¸æ“‡ 1 3 5 7 9")

    # é€™è£¡å¯ä»¥å¯¦ç¾äº’å‹•å¼é¸æ“‡
    # æš«æ™‚è¿”å›é è¨­é¸æ“‡
    return [1, 3, 5, 7, 9]


def ai_final_analysis(selected_items):
    """ç¬¬äºŒéšæ®µï¼šAI æœ€çµ‚åˆ†æèˆ‡æ ¼å¼åŒ–"""
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        print("âŒ GEMINI_API_KEY æœªè¨­å®š")
        return None

    try:
        import google.generativeai as genai

        genai.configure(api_key=api_key)
        model = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
        gen_model = genai.GenerativeModel(model)

        print("ğŸ¤– AI æ­£åœ¨é€²è¡Œæœ€çµ‚åˆ†æèˆ‡æ ¼å¼åŒ–...")

        # æº–å‚™é¸ä¸­çš„æ–°èè³‡æ–™
        selected_data = []
        for item in selected_items:
            selected_data.append(
                {
                    "title": item["original"]["title"],
                    "summary": item["original"].get("summary", ""),
                    "source": item["original"].get("source", ""),
                    "url": item["original"]["url"],
                    "published_at": item["original"]["published_at"],
                    "ai_analysis": item["ai_analysis"],
                }
            )

        # ç”Ÿæˆæ ¼å¼Aï¼šç¤¾ç¾¤å‚³æ’­ç‰ˆ
        format_a_prompt = f"""ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„ AI ç”¢æ¥­å…§å®¹ç­–å±•äººèˆ‡å‰µæ–°å¯¦è¸è€…ã€‚
è«‹ä»¥ç¹é«”ä¸­æ–‡ã€æ™‚å€ Asia/Taipeiï¼Œç‚ºä»¥ä¸‹ {len(selected_data)} å‰‡ AI æ–°èç”¢å‡ºã€æ ¼å¼Aï¼šç¤¾ç¾¤å‚³æ’­ç‰ˆã€‘ã€‚

æ–°èè³‡æ–™ï¼š
{json.dumps(selected_data, ensure_ascii=False, indent=2)}

è«‹æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¼¸å‡ºï¼š

ğŸ·ï¸ã€åˆ†é¡ã€‘æ–°èæ¨™é¡Œ
ğŸ’¡ä¸€å¥è©±é‡é»ï¼ˆâ‰¤20å­—ï¼‰
æ‘˜è¦ï¼ˆ120â€“150å­—ï¼‰ï¼šæ ¸å¿ƒäº‹å¯¦ + 2â€“3é—œéµè¨Šæ¯ + å½±éŸ¿ç¯„åœ

é—œéµæ´å¯Ÿï¼š
* æŠ€è¡“çªç ´ï¼šX
* å¯¦å‹™å½±éŸ¿ï¼šX
* è¡Œå‹•å»ºè­°ï¼šX

å‰µæ–°å¯¦è¸è€…åæ€ï¼š
â†’ è·¨ç•Œé€£çµï¼šX
â†’ å¯¦è¸è·¯å¾‘ï¼šX
â†’ æ ¸å¿ƒå•Ÿç™¼ï¼šX

---

ğŸ“Š æœ€å¾Œç¸½çµ
ã€ä»Šæ—¥ä¸‰å¤§è¶¨å‹¢ã€‘ï¼šåˆ—3é»ï¼ˆæ¯é»â‰¤20å­—ï¼‰
ã€é‡‘å¥æ´å¯Ÿã€‘ï¼š1å¥
ã€ç«‹å³è¡Œå‹•ã€‘ï¼šè§’è‰²ï¼‹æ™‚é–“ï¼‹å…·é«”è¡Œå‹•ï¼‹é‡åŒ–æ•ˆæœ

ä½¿ç”¨ emoji çªå‡ºåˆ†é¡èˆ‡äº®é»ï¼Œèªæ°£å°ˆæ¥­ã€ç°¡æ½”ï¼Œåå‘ç”¢æ¥­è§€é»ã€‚"""

        response_a = gen_model.generate_content(
            format_a_prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.3),
        )

        # ç”Ÿæˆæ ¼å¼Bï¼šAPAå¼•ç”¨æ ¼å¼
        format_b_prompt = f"""è«‹ç‚ºä»¥ä¸‹æ–°èç”Ÿæˆã€æ ¼å¼Bï¼šAPA 7 å¼•ç”¨æ ¼å¼ã€‘ï¼š

{json.dumps(selected_data, ensure_ascii=False, indent=2)}

æ ¼å¼ï¼šAuthor. (Year, Month Day). Title. Publisher/Source. URL"""

        response_b = gen_model.generate_content(
            format_b_prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.1),
        )

        # ç”Ÿæˆæ ¼å¼Cï¼šè¦–è¦ºè¨­è¨ˆç‰ˆ
        format_c_prompt = f"""è«‹ç‚ºä»¥ä¸‹æ–°èç”Ÿæˆã€æ ¼å¼Cï¼šè¦–è¦ºè¨­è¨ˆç‰ˆã€‘ï¼š

{json.dumps(selected_data, ensure_ascii=False, indent=2)}

æ¯å‰‡å…©è¡Œï¼š
ç¬¬1è¡Œï¼š[é¡åˆ¥]
ç¬¬2è¡Œï¼š[ç²¾ç…‰é‡é»10â€“15å­—]"""

        response_c = gen_model.generate_content(
            format_c_prompt,
            generation_config=genai.types.GenerationConfig(temperature=0.2),
        )

        return {
            "format_a": response_a.text.strip(),
            "format_b": response_b.text.strip(),
            "format_c": response_c.text.strip(),
        }

    except Exception as ex:
        print(f"âŒ AI æœ€çµ‚åˆ†æå¤±æ•—ï¼š{ex}")
        return None


def save_results(formats, selected_items):
    """å„²å­˜çµæœ"""
    date_path = today_path()
    out_dir = f"content/{date_path}"
    os.makedirs(out_dir, exist_ok=True)

    # å„²å­˜æ ¼å¼Aï¼šç¤¾ç¾¤å‚³æ’­ç‰ˆ
    with open(f"{out_dir}/format_a_social_tw.md", "w", encoding="utf-8") as f:
        f.write(formats["format_a"])

    # å„²å­˜æ ¼å¼Bï¼šAPAå¼•ç”¨æ ¼å¼
    with open(f"{out_dir}/format_b_apa_tw.md", "w", encoding="utf-8") as f:
        f.write(formats["format_b"])

    # å„²å­˜æ ¼å¼Cï¼šè¦–è¦ºè¨­è¨ˆç‰ˆ
    with open(f"{out_dir}/format_c_design_tw.txt", "w", encoding="utf-8") as f:
        f.write(formats["format_c"])

    # å„²å­˜é¸ä¸­çš„é …ç›®è³‡æ–™
    write_json(f"{out_dir}/selected_items.json", selected_items)

    print(f"âœ… çµæœå·²å„²å­˜è‡³ï¼š{out_dir}/")


def main():
    print("ğŸš€ åŠè‡ªå‹• AI æ–°èè™•ç†ç³»çµ±")
    print("=" * 50)

    # è¼‰å…¥åŸå§‹æ–°è
    items = load_articles()
    if not items:
        print("âŒ æ‰¾ä¸åˆ°åŸå§‹è³‡æ–™ï¼Œè«‹å…ˆåŸ·è¡Œ collect.py")
        return

    print(f"ğŸ“° è¼‰å…¥ {len(items)} å‰‡æ–°è")

    # ç¬¬ä¸€éšæ®µï¼šAI åˆæ­¥è©•åˆ†
    scored_items = ai_initial_scoring(items)
    if not scored_items:
        print("âŒ AI è©•åˆ†å¤±æ•—")
        return

    # ç”Ÿæˆå€™é¸çœ‹æ¿
    generate_candidate_board(scored_items)

    # äººå·¥é¸æ“‡ï¼ˆé€™è£¡å¯ä»¥å¯¦ç¾äº’å‹•å¼é¸æ“‡ï¼‰
    selected_ids = manual_selection_and_processing()
    selected_items = [item for item in scored_items if item["id"] in selected_ids]

    print(f"\nâœ… å·²é¸æ“‡ {len(selected_items)} å‰‡æ–°è")

    # ç¬¬äºŒéšæ®µï¼šAI æœ€çµ‚åˆ†æ
    formats = ai_final_analysis(selected_items)
    if not formats:
        print("âŒ AI æœ€çµ‚åˆ†æå¤±æ•—")
        return

    # å„²å­˜çµæœ
    save_results(formats, selected_items)

    print("\nğŸ‰ åŠè‡ªå‹•è™•ç†å®Œæˆï¼")
    print("ğŸ“ çµæœæª”æ¡ˆï¼š")
    print("   - format_a_social_tw.mdï¼ˆç¤¾ç¾¤å‚³æ’­ç‰ˆï¼‰")
    print("   - format_b_apa_tw.mdï¼ˆAPAå¼•ç”¨æ ¼å¼ï¼‰")
    print("   - format_c_design_tw.txtï¼ˆè¦–è¦ºè¨­è¨ˆç‰ˆï¼‰")


if __name__ == "__main__":
    main()
